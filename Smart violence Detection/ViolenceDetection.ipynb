{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__  import division\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from matplotlib.patches import Rectangle\n",
    "from PIL import Image\n",
    "from PIL import ImageEnhance\n",
    "from matplotlib.patches import Circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17905682091569545295\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4183621632\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 11638780771546671430\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from localfiletesting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "print(tf. __version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgenhance():\n",
    "  image1 = Image.open('savedImage.jpg')\n",
    "  curr_bri = ImageEnhance.Sharpness(image1)\n",
    "  new_bri = 1.3\n",
    "  img_brightened = curr_bri.enhance(new_bri)\n",
    "  im1 = img_brightened.save(\"bright.jpg\")\n",
    "\n",
    "  image2 = Image.open('bright.jpg')\n",
    "  curr_col = ImageEnhance.Color(image2)\n",
    "  new_col = 1.5\n",
    "  img_col = curr_col.enhance(new_col)\n",
    "  im2 = img_col.save(\"finalImage.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_faces(filename, result_list):\n",
    "    # load the image\n",
    "    data = pyplot.imread(filename)\n",
    "    # plot each face as a subplot\n",
    "    for i in range(len(result_list)):\n",
    "        # get coordinates\n",
    "        x1, y1, width, height = result_list[i]['box']\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "        # define subplot\n",
    "        pyplot.subplot(1, len(result_list), i+1)\n",
    "        pyplot.axis('off')\n",
    "        # plot face\n",
    "        pyplot.imshow(data[y1:y2, x1:x2])\n",
    "    # show the plot\n",
    "    pyplot.savefig(\"faces.png\")\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Det_Model(tf,wight='fightw.hdfs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Violence detected here ...\n",
      "1/1 [==============================] - 1s 705ms/step\n",
      "1/1 [==============================] - 1s 513ms/step\n",
      "1/1 [==============================] - 0s 414ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 273ms/step\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "4/4 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 282ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n",
      "Violence detected here ...\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Violence detected here ...\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Violence detected here ...\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Violence detected here ...\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Violence detected here ...\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Violence detected here ...\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Violence detected here ...\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Violence detected here ...\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Violence detected here ...\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Violence detected here ...\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Violence detected here ...\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Violence detected here ...\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "from tkinter import filedialog as fd\n",
    "import tkinter\n",
    "root = tkinter.Tk()\n",
    "root.withdraw()\n",
    "V_test = fd.askopenfilename()\n",
    "cap = cv2.VideoCapture(V_test)\n",
    "i = 0\n",
    "frames = np.zeros((30, 160, 160, 3), dtype=float)\n",
    "old = []\n",
    "j = 0\n",
    "truecount = 0\n",
    "imagesaved=0\n",
    "filename = 'savedImage.jpg'\n",
    "my_image = 'finalImage.jpg'\n",
    "face_image = 'faces.png'\n",
    "ysdatav2 = np.zeros((1, 30, 160, 160, 3), dtype=float)\n",
    "ysdatav2[0][:][:] = frames\n",
    "prediction = pred_fight(model,ysdatav2,acuracy=0.96)\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "  \n",
    "    # describe the type of font to be used \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    #display the text on every frame\n",
    "    text_color = (0, 255, 0) #Green\n",
    "    label = prediction[0]\n",
    "    if label: # Violence\n",
    "        text_color = (0, 0, 255) # red\n",
    "        truecount = truecount + 1\n",
    "    else:# No Violence\n",
    "        text_color = (0, 255, 0)\n",
    "    text = \"Violence: {}\".format(label)\n",
    "    cv2.putText(frame, text, (35, 50), font,1.25, text_color, 3)\n",
    "    if i > 29:\n",
    "        ysdatav2 = np.zeros((1,30,160,160, 3), dtype=float)\n",
    "        ysdatav2[0][:][:] = frames\n",
    "        prediction = pred_fight(model,ysdatav2,acuracy=0.96)\n",
    "        if label == True:\n",
    "            cv2.imshow('video', frame)\n",
    "            print('Violence detected here ...')\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "            vio = cv2.VideoWriter(\"./videos/output-\"+str(j)+\".avi\", fourcc, 10.0, (fwidth,fheight))\n",
    "            #vio = cv2.VideoWrite\"./videos/output-\"+str(j)+\".mp4\", cv2.VideoWriter_fourcc(*'mp4v'), 10, (300, 400))\n",
    "            for frameinss in old:\n",
    "                vio.write(frameinss)\n",
    "            vio.release()\n",
    "        i = 0\n",
    "        j += 1\n",
    "        frames = np.zeros((30, 160, 160, 3), dtype=float)\n",
    "        old = []\n",
    "    else:\n",
    "        try:\n",
    "            frm = resize(frame,(160,160,3))\n",
    "            old.append(frame)\n",
    "            fshape = frame.shape\n",
    "            fheight = fshape[0]\n",
    "            fwidth = fshape[1]\n",
    "            frm = np.expand_dims(frm,axis=0)\n",
    "            if(np.max(frm)>1):\n",
    "                frm = frm/255\n",
    "            frames[i][:] = frm\n",
    "        \n",
    "            i+=1\n",
    "            cv2.imshow('video', frame)\n",
    "        except:\n",
    "            pass\n",
    "            if cv2.waitKey(1):\n",
    "                break\n",
    "        \n",
    "    if(truecount == 40):\n",
    "        if(imagesaved == 0):\n",
    "            if(label):\n",
    "                cv2.imwrite(filename,frame)\n",
    "                imagesaved = 1\n",
    "        imgenhance()\n",
    "        # load image from file\n",
    "        pixels = cv2.imread(my_image)\n",
    "        # create the detector, using default weights\n",
    "        detector = MTCNN()\n",
    "        # detect faces in the image\n",
    "        faces = detector.detect_faces(pixels)\n",
    "        # display faces on the original image\n",
    "        draw_faces(my_image, faces)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
